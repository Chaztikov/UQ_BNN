{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertainty quantification using \"DRIVE: Digital Retinal Images for Vessel Extraction\" dataset\n",
    " \n",
    "__author__: Yongchan Kwon\n",
    "\n",
    "This note shows an example of the use of the method introduced in the paper \"Uncertainty quantification using Bayesian neural networks in classification: Application to biomedical segmentation\".\n",
    "\n",
    "This notebook is based on the Walter de Back's amazing notebook https://gitlab.com/wdeback/dl-keras-tutorial/blob/master/notebooks/3-cnn-segment-retina-uncertainty.ipynb I really recommend to see together. \n",
    "\n",
    "**Reference**\n",
    "\n",
    "- J.J. Staal, M.D. Abramoff, M. Niemeijer, M.A. Viergever, B. van Ginneken, \"Ridge based vessel segmentation in color images of the retina\", IEEE Transactions on Medical Imaging, 2004, vol. 23, pp. 501-509.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, glob\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "np.random.seed(20180621)\n",
    "\n",
    "from skimage.external import tifffile # read tiff images\n",
    "from skimage.io import imread # read gif images\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import backend as K\n",
    "import seaborn as sns\n",
    "\n",
    "from model import *\n",
    "import utils\n",
    "import time\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend:  tensorflow\n",
      "Image_data_format:  channels_last\n"
     ]
    }
   ],
   "source": [
    "print('Backend: ', K.backend())\n",
    "print('Image_data_format: ', K.image_data_format())\n",
    "N_train = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/skimage/external/tifffile/tifffile.py:2611: RuntimeWarning: py_decodelzw encountered unexpected end of stream\n",
      "  strip = decompress(strip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of raw train data:  (20, 584, 565, 3)\n",
      "shape of raw test data:  (20, 584, 565, 3)\n"
     ]
    }
   ],
   "source": [
    "# load training images\n",
    "fns = sorted(glob.glob('./input/training/images/*.tif'))\n",
    "x_train = np.array([tifffile.imread(fn) for fn in fns])\n",
    "\n",
    "# load test images\n",
    "fns = sorted(glob.glob('./input/test/images/*.tif'))\n",
    "x_test = np.array([tifffile.imread(fn) for fn in fns])\n",
    "print('shape of raw train data: ', x_train.shape)\n",
    "print('shape of raw test data: ',x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (20, 584, 565, 1)\n",
      "test shape: (20, 584, 565, 1)\n"
     ]
    }
   ],
   "source": [
    " # load training annotations\n",
    "fns = sorted(glob.glob('./input/training/1st_manual/*.gif'))\n",
    "y_train = np.array([imread(fn) for fn in fns]) # read images\n",
    "y_train = np.expand_dims(y_train, -1) # add channels dimension\n",
    "\n",
    "# load test annotations\n",
    "fns = sorted(glob.glob('./input/test/1st_manual/*.gif'))\n",
    "y_test = np.array([imread(fn) for fn in fns]) # read images\n",
    "y_test = np.expand_dims(y_test, -1) # add channels dimension\n",
    "print('train shape:', y_train.shape)\n",
    "print('test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprecossing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 0.0, max: 1.0, shape: (20, 584, 565, 3), type: float32\n",
      "min: 0.0, max: 1.0, shape: (20, 584, 565, 3), type: float32\n",
      "min: 0.0, max: 1.0, shape: (20, 584, 565, 1), type: float32\n",
      "min: 0.0, max: 1.0, shape: (20, 584, 565, 1), type: float32\n"
     ]
    }
   ],
   "source": [
    "x_train = utils.preprocess(x_train)\n",
    "x_test = utils.preprocess(x_test)\n",
    "\n",
    "y_train = utils.preprocess(y_train)\n",
    "y_test = utils.preprocess(y_test)\n",
    "\n",
    "X_train, Y_train = utils.get_random_snippets(x_train, y_train, number=N_train, size=(96,96))\n",
    "X_test, Y_test = utils.get_random_snippets(x_test, y_test, number=1000, size=(96,96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters:  1115265\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "Test loss, acc, dice, precision, recall): [0.16768202114105224, 0.945465814113617, 0.6613291058540344, 0.7088055973052978, 0.6202359004020691]\n"
     ]
    }
   ],
   "source": [
    "unet_16_model = UNet(N_filters=16)\n",
    "unet_16_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy', dice_coefficient, precision_smooth, recall_smooth])\n",
    "print(\"Number of parameters: \", unet_16_model.count_params())\n",
    "info_check_string='./weights/DRIVE_u_net_16.hdf5'\n",
    "early_stopping=EarlyStopping(monitor='val_loss', patience=10)\n",
    "model_checkpoint=ModelCheckpoint(info_check_string, monitor='loss', save_best_only=True)\n",
    "\n",
    "history = unet_16_model.fit(X_train, Y_train,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      shuffle=True,\n",
    "                      verbose=0,\n",
    "                      validation_split=0.2, # 4 samples are used for a validation set\n",
    "                      callbacks=[early_stopping, model_checkpoint]) \n",
    "\n",
    "score = unet_16_model.evaluate(X_test, Y_test, verbose=1)\n",
    "print('Test loss, acc, dice, precision, recall):', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters:  1115265\n",
      "1000/1000 [==============================] - 2s 2ms/step\n",
      "Test loss, acc, dice, precision, recall): [0.23471113443374633, 0.9232702922821044, 0.4888037633895874, 0.6897055797576904, 0.37910134983062743]\n"
     ]
    }
   ],
   "source": [
    "unet_32_model = UNet(N_filters=32)\n",
    "unet_32_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy', dice_coefficient, precision_smooth, recall_smooth])\n",
    "print(\"Number of parameters: \", unet_32_model.count_params())\n",
    "info_check_string='./weights/DRIVE_u_net_32.hdf5'\n",
    "early_stopping=EarlyStopping(monitor='val_loss', patience=10)\n",
    "model_checkpoint=ModelCheckpoint(info_check_string, monitor='loss', save_best_only=True)\n",
    "\n",
    "history = unet_32_model.fit(X_train, Y_train,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      shuffle=True,\n",
    "                      verbose=0,\n",
    "                      validation_split=0.2, # 4 samples are used for a validation set\n",
    "                      callbacks=[early_stopping, model_checkpoint]) \n",
    "\n",
    "score = unet_32_model.evaluate(X_test, Y_test, verbose=1)\n",
    "print('Test loss, acc, dice, precision, recall):', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters:  293761\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "Test loss, acc, dice, precision, recall): [0.16264933681488036, 0.9440366797447205, 0.6333848075866699, 0.6693824739456177, 0.6015564303398132]\n"
     ]
    }
   ],
   "source": [
    "small_16_model = Small_UNet(N_filters=16)\n",
    "small_16_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy', dice_coefficient, precision_smooth, recall_smooth])\n",
    "print(\"Number of parameters: \", small_16_model.count_params())\n",
    "info_check_string='./weights/DRIVE_200_small_16.hdf5'\n",
    "early_stopping=EarlyStopping(monitor='val_loss', patience=10)\n",
    "model_checkpoint=ModelCheckpoint(info_check_string, monitor='loss', save_best_only=True)\n",
    "\n",
    "history = small_16_model.fit(X_train, Y_train,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      shuffle=True,\n",
    "                      verbose=0,\n",
    "                      validation_split=0.2, # 4 samples are used for a validation set\n",
    "                      callbacks=[early_stopping, model_checkpoint]) \n",
    "\n",
    "score = small_16_model.evaluate(X_test, Y_test, verbose=1)\n",
    "print('Test loss, acc, dice, precision, recall):', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters:  1170689\n",
      "1000/1000 [==============================] - 2s 2ms/step\n",
      "Test loss, acc, dice, precision, recall): [0.2231516089439392, 0.9333513450622558, 0.5836484122276306, 0.718721842288971, 0.49227611207962035]\n"
     ]
    }
   ],
   "source": [
    "small_32_model = Small_UNet(N_filters=32)\n",
    "small_32_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy', dice_coefficient, precision_smooth, recall_smooth])\n",
    "print(\"Number of parameters: \", small_32_model.count_params())\n",
    "info_check_string='./weights/DRIVE_200_small_32.hdf5'\n",
    "early_stopping=EarlyStopping(monitor='val_loss', patience=10)\n",
    "model_checkpoint=ModelCheckpoint(info_check_string, monitor='loss', save_best_only=True)\n",
    "\n",
    "history = small_32_model.fit(X_train, Y_train,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      shuffle=True,\n",
    "                      verbose=0,\n",
    "                      validation_split=0.2, # 4 samples are used for a validation set\n",
    "                      callbacks=[early_stopping, model_checkpoint]) \n",
    "\n",
    "score = small_32_model.evaluate(X_test, Y_test, verbose=1)\n",
    "print('Test loss, acc, dice, precision, recall):', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian neural network: stochastic feed forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It takes a time !! \n",
    "num = len(X_test)\n",
    "model_list = [unet_16_model, unet_32_model, small_16_model, small_32_model]\n",
    "model_name_list = ['unet_16','unet_32','small_16','small_32']\n",
    "result_dict = {}\n",
    "for ind, model in enumerate(model_list):\n",
    "    alea_list = []\n",
    "    epis_list = []\n",
    "    for i in range(num):\n",
    "        image = X_test[i]\n",
    "        gt    = Y_test[i]\n",
    "        prediction, aleatoric, epistemic, scores = utils.predict(model, image, gt, T=5)\n",
    "        alea_list.append(np.mean(aleatoric))\n",
    "        epis_list.append(np.mean(epistemic))\n",
    "    \n",
    "    result_dict.update({model_name_list[ind] : \n",
    "    [np.mean(alea_list), np.std(alea_list),\n",
    "     np.mean(epis_list), np.std(epis_list)]} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'small_16': [0.035315458, 0.009498992, 0.0032370426, 0.0016550159],\n",
       " 'small_32': [0.023589768, 0.00749878, 0.0027492752, 0.0018435583],\n",
       " 'unet_16': [0.028418148, 0.0077059194, 0.0035906862, 0.001790707],\n",
       " 'unet_32': [0.026688866, 0.0067304643, 0.001720618, 0.0011788398]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters:  1115265\n",
      "Number of parameters:  4452097\n",
      "Number of parameters:  293761\n",
      "Number of parameters:  1170689\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of parameters: \", unet_16_model.count_params())\n",
    "print(\"Number of parameters: \", unet_32_model.count_params())\n",
    "print(\"Number of parameters: \", small_16_model.count_params())\n",
    "print(\"Number of parameters: \", small_32_model.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
